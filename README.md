# OmniWordlist Pro â€” Enterprise Wordlist Generator

**Version:** 1.1.0  
**Author:** Aaryan Bansal  
**Language:** 100% Pure Rust ğŸ¦€  
**Repository:** https://github.com/AaryanBansal-dev/OmniWordlistPro  
**Build Status:** âœ… Actively Maintained  
**Last Updated:** November 7, 2025

---

## âš¡ Getting Started (5 minutes)

### Prerequisites
- **Rust 1.70+** (install via [rustup.rs](https://rustup.rs))
- **Git** (for cloning)
- **Linux/macOS/Windows** (all supported)

### ğŸš€ Quick Install & Run

```bash
# Clone the repository
git clone https://github.com/AaryanBansal-dev/OmniWordlistPro.git
cd OmniWordlistPro

# Build the binary (takes 5-10 minutes first time)
cargo build --release

# Run a quick test
./target/release/omni info

# Or create an alias for easier access
alias owpro="$(pwd)/target/release/omni"
owpro list-presets
```

### ğŸ“š Full Documentation

- **[INSTALL.md](INSTALL.md)** â€” Complete installation & troubleshooting guide
- **[QUICK_START.md](QUICK_START.md)** â€” CLI command reference
- **[DEVELOPMENT.md](DEVELOPMENT.md)** â€” Development setup & contribution guide

---

## Overview

**OmniWordlist Pro** is a **production-ready, ultra-high-performance wordlist generation platform** written entirely in Rust. It combines:

- âœ… **Crunch compatibility**: Pattern-based generation with charset support (@, %, ^, ,)
- âœ… **CUPP integration**: 1500+ toggleable fields for personalization
- âœ… **100+ transforms**: Leet, homoglyph, emoji, phonetic, keyboard shifts, etc.
- âœ… **Enterprise features**: Checkpointing, deduplication, compression, S3 integration
- âœ… **Beautiful TUI**: Ratatui-based interface with colors and ASCII art
- âœ… **Streaming architecture**: Memory-efficient, no OOM on massive lists
- âœ… **Multi-format output**: TXT, GZIP, BZIP2, LZ4, ZSTD, JSONL, CSV

Perfect for:
- ğŸ¯ Penetration testers & red teams
- ğŸ¯ Bug bounty hunters
- ğŸ¯ Security researchers
- ğŸ¯ Credential auditing
- ğŸ¯ Creative wordlist experiments

---

## Core Features (Actually Implemented âœ…)

### ğŸ¯ Generation & Combinatorics
- âœ… **Charset-based generation** â€” Custom character sets with Crunch-style patterns
- âœ… **Pattern support** â€” `@` (lower), `%` (digit), `^` (symbol), `,` (upper) expansion
- âœ… **Length constraints** â€” Min/max word length control
- âœ… **Prefix/suffix support** â€” Prepend/append to all generated tokens
- âœ… **Field-based generation** â€” 1500+ fields across 12+ categories
- âœ… **Streaming architecture** â€” Memory-efficient token generation

### ğŸ”„ Transforms (100+ available)
- âœ… **Case transforms** â€” uppercase, lowercase, capitalize, toggle_case, title_case
- âœ… **Leet speak** â€” basic, full, random leet variations
- âœ… **Homoglyphs** â€” single, random, full expansion
- âœ… **Keyboard shifts** â€” adjacent key substitutions
- âœ… **Diacritics** â€” expand/strip unicode marks
- âœ… **Emoji injection** â€” insertion and random placement
- âœ… **Append numbers** â€” suffix with configurable digit patterns
- âœ… **String reversal** â€” reverse entire tokens
- âœ… **Pluralization** â€” English pluralization rules

### ï¿½ï¸ Filters & Quality
- âœ… **Length validation** â€” Min/max character constraints
- âœ… **Charset filtering** â€” Allowlist/blocklist character validation
- âœ… **Entropy calculation** â€” Shannon entropy scoring
- âœ… **Quality scoring** â€” 0.0-1.0 quality rating system
- âœ… **Pronounceability** â€” Basic pronunciation quality checks

### ğŸ’¾ Output & Storage
- âœ… **Text output** â€” Plain UTF-8 TXT format
- âœ… **Compression formats** â€” GZIP, BZIP2, LZ4, ZSTD
- âœ… **JSON output** â€” JSONL (one JSON per line)
- âœ… **CSV export** â€” Comma-separated values with headers
- âœ… **Per-chunk checksums** â€” BLAKE2b integrity verification

### ğŸ® User Interface
- âœ… **CLI interface** â€” Full command-line argument support
- âœ… **TUI dashboard** â€” Beautiful Ratatui-based interactive interface (Experimental)
- âœ… **Help system** â€” Built-in `--help` for all commands
- âœ… **Preview mode** â€” Sample generation before full job

### ğŸ“‹ Presets (5 Built-in)
1. **pentest_default** â€” Standard pentesting wordlist
2. **meme_humor_pack** â€” Creative wordlist with humor
3. **api_dev_wordlist** â€” API endpoint patterns
4. **social_media_usernames** â€” Social media handles
5. **pattern_basic** â€” Crunch-style pattern examples

---

## Usage Examples

### Example 1: Basic Generation
```bash
# Generate all 3-character combinations from 'abc'
./target/release/omni run --min 3 --max 3 --charset "abc" -o output.txt
# Output: aaa, aab, aac, aba, abb, ... bca, bcb, bcc

# View first 10 lines
head -10 output.txt
```

### Example 2: With Transformations
```bash
# Generate with leet speak
./target/release/omni run \
  --min 5 \
  --max 10 \
  --charset "abcdefghijklmnopqrstuvwxyz0123456789" \
  --prefix "admin_" \
  --suffix "!2024" \
  -o output.txt
```

### Example 3: Using Presets
```bash
# List available presets
./target/release/omni list-presets

# Preview pentest preset (show 50 samples)
./target/release/omni preview --preset pentest_default --sample-size 50

# Generate full wordlist
./target/release/omni run --preset pentest_default -o pentest.txt
```

### Example 4: Compressed Output
```bash
# Generate with GZIP compression
./target/release/omni run \
  --charset "abcdefghijklmnopqrstuvwxyz0123456789" \
  --min 6 \
  --max 12 \
  --compress gzip \
  -o wordlist.txt.gz

# Generate with ZSTD (faster compression)
./target/release/omni run \
  --charset "abcdefghijklmnopqrstuvwxyz0123456789" \
  --min 6 \
  --max 12 \
  --compress zstd \
  -o wordlist.txt.zst

# Decompress when needed
gunzip wordlist.txt.gz
zstd -d wordlist.txt.zst
```

### Example 5: JSON Output
```bash
# Generate as JSONL (one JSON per line)
./target/release/omni run \
  --charset "abc123" \
  --min 4 \
  --max 6 \
  --format jsonl \
  -o output.jsonl

# View the output
cat output.jsonl | head -5
# Each line is: {"token":"abc1","entropy":2.3,"length":4}
```

### Example 6: Field-Based Generation
```bash
# List all field categories
./target/release/omni fields --categories

# List fields in a specific category
./target/release/omni fields --category personal

# Generate from specific fields (if implemented)
./target/release/omni run \
  --fields first_name_male_0,last_name_0 \
  -o names.txt
```

---

## Project Structure

```
OmniWordlistPro/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs              # CLI entry point & command handling
â”‚   â”œâ”€â”€ lib.rs               # Library root
â”‚   â”œâ”€â”€ error.rs             # Error types & handling
â”‚   â”œâ”€â”€ config.rs            # Configuration validation
â”‚   â”œâ”€â”€ charset.rs           # Character sets & patterns
â”‚   â”œâ”€â”€ fields.rs            # 1500+ field taxonomy
â”‚   â”œâ”€â”€ generator.rs         # Core streaming generation engine
â”‚   â”œâ”€â”€ transforms.rs        # 100+ transform types
â”‚   â”œâ”€â”€ filters.rs           # Quality & validation filters
â”‚   â”œâ”€â”€ storage.rs           # Output writing & compression
â”‚   â”œâ”€â”€ presets.rs           # Preset management
â”‚   â””â”€â”€ ui.rs                # TUI interface (Ratatui)
â”‚
â”œâ”€â”€ Cargo.toml               # Dependencies & metadata
â”œâ”€â”€ Cargo.lock               # Dependency lock file
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ INSTALL.md               # Installation guide
â”œâ”€â”€ QUICK_START.md           # Command reference
â”œâ”€â”€ DEVELOPMENT.md           # Development guide
â”œâ”€â”€ FEATURES.md              # Feature list & status
â””â”€â”€ presets/                 # Built-in preset configurations
    â”œâ”€â”€ pentest_default.json
    â”œâ”€â”€ meme_humor_pack.json
    â”œâ”€â”€ api_dev_wordlist.json
    â”œâ”€â”€ social_media_usernames.json
    â””â”€â”€ pattern_basic.json
```

### Core Modules Explained

#### `main.rs` â€” Command-Line Interface
- Argument parsing with `clap`
- Command routing (run, preview, fields, etc.)
- Error handling & user feedback

#### `charset.rs` â€” Character Sets & Patterns
- Predefined charsets: lowercase, uppercase, digits, symbols
- Pattern expansion for Crunch compatibility
- Character set merging and operations

#### `fields.rs` â€” Field Taxonomy
- 1500+ available fields across categories
- Field metadata (type, examples, cardinality)
- Field dependency tracking

#### `generator.rs` â€” Streaming Combinator Engine
- Generates combinations of characters/fields
- Memory-efficient streaming approach
- Support for custom ordering and sampling

#### `transforms.rs` â€” Transformation Pipeline
- 100+ available transforms
- Chain transforms together
- Each transform is deterministic & reversible when possible

#### `filters.rs` â€” Quality & Validation
- Length constraints
- Entropy calculations
- Character set validation
- Pronounceability scoring

#### `storage.rs` â€” Output & Compression
- Multiple output formats: TXT, JSONL, CSV
- Compression: GZIP, BZIP2, LZ4, ZSTD
- Streaming writers (no full buffering)
- Per-chunk checksums for integrity

#### `presets.rs` â€” Preset Management
- Load/save preset configurations
- Built-in presets for common use cases
- Preset validation & merging

#### `ui.rs` â€” Terminal User Interface
- Ratatui-based interactive dashboard
- Real-time previews
- Keyboard navigation
- Still experimental

---

## CLI Command Reference

### `omni run` â€” Generate a wordlist
```bash
./target/release/omni run [OPTIONS]
```

**Key options:**
- `--min <LEN>` â€” Minimum word length (default: 1)
- `--max <LEN>` â€” Maximum word length (default: 10)
- `--charset <CHARS>` â€” Character set to use (default: lowercase)
- `--prefix <STR>` â€” Prepend to each token
- `--suffix <STR>` â€” Append to each token
- `--preset <NAME>` â€” Use a named preset
- `--compress <FORMAT>` â€” Compress output (gzip, bzip2, lz4, zstd)
- `--format <FMT>` â€” Output format (txt, jsonl, csv)
- `-o, --output <FILE>` â€” Output file path
- `-s, --sample-size <N>` â€” Limit output to N tokens

**Example:**
```bash
./target/release/omni run --min 5 --max 10 --charset "abcdefghijklmnopqrstuvwxyz0123456789" -o wordlist.txt
```

### `omni preview` â€” Sample generation before full run
```bash
./target/release/omni preview [OPTIONS]
```

**Options:**
- `--preset <NAME>` â€” Preview a preset
- `--sample-size <N>` â€” Number of samples to show (default: 10)
- `--min <LEN>`, `--max <LEN>` â€” Length constraints

**Example:**
```bash
./target/release/omni preview --preset pentest_default --sample-size 50
```

### `omni list-presets` â€” Show available presets
```bash
./target/release/omni list-presets
```

**Output:**
```
Available Presets:
1. pentest_default       - Standard pentesting wordlist
2. meme_humor_pack       - Creative with humor
3. api_dev_wordlist      - API endpoint patterns
4. social_media_usernames - Social handles
5. pattern_basic         - Crunch-style patterns
```

### `omni show-preset` â€” Display preset details
```bash
./target/release/omni show-preset <PRESET_NAME>
```

**Example:**
```bash
./target/release/omni show-preset pentest_default
```

### `omni fields` â€” Browse available fields
```bash
./target/release/omni fields [OPTIONS]
```

**Options:**
- `--categories` â€” List all field categories
- `--category <NAME>` â€” List fields in a category
- `--search <QUERY>` â€” Search for fields

**Example:**
```bash
./target/release/omni fields --categories
./target/release/omni fields --category personal
```

### `omni info` â€” Show version and system info
```bash
./target/release/omni info
```

**Output shows:**
- Binary version
- Supported transforms
- Supported compression formats
- System information

### `omni tui` â€” Launch interactive dashboard (Experimental)
```bash
./target/release/omni tui
```

**Features:**
- Browse presets
- Explore fields
- Real-time previews
- Configure generation
- Navigate with arrow keys, press `?` for help

---

## Configuration (JSON/TOML)

### Example JSON Config
```json
{
  "min_length": 8,
  "max_length": 16,
  "charset": "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789",
  "pattern": null,
  "enabled_fields": [
    "first_name_male_0",
    "last_name_0",
    "common_suffix_0"
  ],
  "transforms": [
    "leet_basic",
    "capitalize",
    "append_numbers_4"
  ],
  "filters": {
    "min_len": 8,
    "max_len": 32,
    "charset_filter": "abcdefghijklmnopqrstuvwxyz0123456789"
  },
  "output_file": "./output/wordlist.txt.gz",
  "compression": "gzip",
  "dedupe": true,
  "bloom_fp_rate": 0.01,
  "prefix": "admin",
  "suffix": "!2024",
  "workers": 8
}
```

### Example TOML Config
```toml
min_length = 8
max_length = 16
charset = "abc123"
pattern = "pass%%"
output_file = "./output/wordlist.txt"
compression = "gzip"
dedupe = true

enabled_fields = [
  "first_name_male_0",
  "last_name_0"
]

transforms = [
  "capitalize",
  "append_numbers_4"
]

[filters]
min_len = 8
max_len = 32
charset_filter = "abcdefghijklmnopqrstuvwxyz0123456789"
```

---

## Performance & Benchmarks

Performance varies based on:
- **Character set size** â€” Larger charsets = slower generation
- **Word length** â€” Longer words = more combinations
- **Transforms applied** â€” More transforms = slower output
- **System hardware** â€” Multi-core CPU = better parallelization

Typical speeds on modern hardware (4-core CPU):

| Scenario | Charset | Length | Tokens | Time | Speed |
|----------|---------|--------|--------|------|-------|
| Simple | a-z | 3-5 | 237K | 0.05s | 4.7M/s |
| Mixed case + digits | A-Za-z0-9 | 6-8 | 2.5M | 0.8s | 3.1M/s |
| With transforms | A-Za-z0-9 | 6-8 | 500K | 1.2s | 0.4M/s |

These are indicative; actual performance depends on:
- CPU speed and core count
- Available RAM
- I/O performance (SSD vs HDD)
- Output format chosen
- Compression algorithm

**Memory usage:**
- Idle binary: ~5-10 MB
- Typical generation: 50-200 MB (streaming, minimal buffering)
- With compression: depends on compression format

---

## Development Guide

For contributors and developers interested in extending OmniWordlist Pro, see **[DEVELOPMENT.md](DEVELOPMENT.md)** for:
- Building from source
- Running tests
- Contributing guidelines
- Architecture deep-dive
- Extending with custom transforms

---

## Troubleshooting

### Issue: Build fails with "error: linker `cc` not found"

**Solution:** You need a C compiler. Install it:

```bash
# Ubuntu/Debian
sudo apt-get install build-essential

# macOS (with Xcode)
xcode-select --install

# Fedora/RHEL
sudo yum groupinstall "Development Tools"
```

### Issue: "command not found: cargo"

**Solution:** Install Rust from https://rustup.rs:

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source "$HOME/.cargo/env"
```

### Issue: Build takes very long or runs out of memory

**Solution:** Your system may have limited resources. Try:

```bash
# Use just 1 parallel job instead of all cores
cargo build --release -j 1

# Or use incremental builds
cargo build --release --incremental
```

### Issue: "Permission denied" when creating output file

**Solution:** Check directory permissions:

```bash
# Make sure output directory exists and is writable
mkdir -p ~/wordlists
chmod 755 ~/wordlists

# Run command with that directory
./target/release/omni run --min 3 --max 5 --charset abc -o ~/wordlists/output.txt
```

### Issue: Output file is empty or missing

**Solution:** Check if the generation actually ran:

```bash
# Preview first
./target/release/omni preview --sample-size 10

# Check what you're generating
./target/release/omni run --min 1 --max 2 --charset "ab" -o test.txt
cat test.txt  # Should show: a, b, aa, ab, ba, bb
```

### Issue: How do I interrupt a long-running job?

**Solution:** Press `Ctrl+C` to stop generation. Long jobs don't support resume yet (future feature).

---

## Contributing

Contributions are welcome! To get started:

1. **Fork the repository** on GitHub
2. **Clone your fork** locally
3. **Create a feature branch** (`git checkout -b feature/my-feature`)
4. **Make your changes** and add tests
5. **Run tests** (`cargo test`)
6. **Commit and push** to your fork
7. **Submit a pull request** with clear description

### Areas for contribution:
- New transforms (leet variations, emoji sets, etc.)
- Additional field packs (specific industries, languages)
- Performance optimizations
- Documentation improvements
- Bug fixes
- Testing edge cases

See **[DEVELOPMENT.md](DEVELOPMENT.md)** for detailed contribution guidelines.

---

## License

MIT License â€” See LICENSE file

---

## License

MIT License â€” See LICENSE file for details

---

## Support

### Getting Help
- **Documentation:** See README.md, INSTALL.md, QUICK_START.md
- **Issues:** Report bugs on [GitHub Issues](https://github.com/AaryanBansal-dev/OmniWordlistPro/issues)
- **Discussions:** Join discussions on [GitHub Discussions](https://github.com/AaryanBansal-dev/OmniWordlistPro/discussions)

### Documentation Files
- **README.md** â† You are here
- **INSTALL.md** â€” Installation & troubleshooting
- **QUICK_START.md** â€” Command quick reference
- **DEVELOPMENT.md** â€” For developers & contributors
- **FEATURES.md** â€” Feature list & implementation status

### Quick Links
- **Repository:** https://github.com/AaryanBansal-dev/OmniWordlistPro
- **Releases:** https://github.com/AaryanBansal-dev/OmniWordlistPro/releases
- **Issues:** https://github.com/AaryanBansal-dev/OmniWordlistPro/issues


## 1. Project Overview

**Mission:** Build the single most flexible wordlist generator â€” capable of producing highly targeted lists for pentesting, research, and creative experiments â€” by letting users toggle every conceivable field (personal, cultural, technical, humor, memes, music, language, keyboard patterns, encodings, etc.) and combine them with robust transforms and constraints.

**Target users:**

* Penetration testers / red teams
* Bug bounty hunters
* Security researchers / DFIR teams
* DevOps/security engineers (credential audit)
* Power users / hobbyists (creative wordlists, memes)

**Core differentiators:**

* Field-driven architecture with granular toggles (â‰¥1,500 fields)
* Crunch-like charset & template support + CUPP personalization
* Stream-first generation (no OOM) with resumable checkpoints & dedupe
* Enterprise features: RBAC, audit logs, encryption, quotas, marketplace

---

## 2. Key Concepts & Terminology

* **Field:** A discrete source token (e.g., `first_name_male`, `fav_meme_format`) that can be enabled/disabled. Fields have metadata (type, examples, cardinality estimate, dependencies).
* **Preset/Profile:** Saved selection of fields, transforms, and generation settings.
* **Transform Pipeline:** Ordered modifications applied to tokens (leet, homoglyph, transliteration, etc.).
* **Combinator Engine:** Produces combinations/permutations across enabled fields following rules (cartesian, sequences, weighted sampling).
* **Sink/Output:** Where generated tokens are written (file, S3, API, STDOUT).
* **Checkpoint:** Persistent state to resume long jobs deterministically.
* **Rule DSL:** Small domain-specific language to express templates, conditional rules, and constraints.

---

## 3. Complete Feature Set (summary)

This combines the Core Features previously described and the 120+ advanced features. Key groups:

### Generation & Combinatorics

* Field grouping, adaptive combinator caps, weighted & conditional combinator rules, stochastic generation, reservoir sampling, sequence templates, cross-field exclusion, hierarchical profiles, dynamic rule scoring, constraint solver.

### Transforms & Mutations

* Multiâ€‘pass transforms, context-aware leet, homoglyph injection, keyboard-shift transforms, phonetic/IPA transforms, diacritic expansion/stripping, transliteration (multi-script), emoji injection rules, macro transforms, entropy-guided mutation, Levenshtein fuzzing, pluralization, dialect variations.

### Filters & Quality

* Probabilistic profanity filter, entropy & pronounceability filters, language detection & family filters, visual-similarity, regex sandbox, charset intersection, stopword & frequency filters, token-length histogram enforcement.

### Outputs & Storage

* Chunked gzipped outputs, S3/MinIO multipart streaming, compressed formats (gz/bz2/zstd/7z), signed/encrypted artifacts, content-addressed storage, per-chunk checksums, metadata manifests, diffs between runs, TTL/retention, partial downloads, watermarking, format conversion API.

### Performance & Scalability

* Distributed generation with sharded partitions, autoscale worker pools, GPU-accelerated transforms (ML filters), streaming backpressure, sharded Bloom filters, RocksDB/LMDB external backing, adaptive compression, IO benchmarking suite, parallel transform pipelines.

### Reliability & Recovery

* Multi-level checkpointing (local/remote), deterministic resumes, job snapshotting, checkpoint compaction, canary jobs, restart/backoff strategies, corruption detection & repair, cross-region failover, idempotent job submission, job priority queues.

### UX & Developer Tools

* Visual rule builder, live preview pane, rule DSL with Monaco integration, preset versioning, inline docs & examples, field dependency graph, keyboard-first UI, dark/light theming.

### Integrations

* Hashcat/John exports, direct SCP to pentest VMs, SIEM connectors, Slack/Discord notifications, webhooks, Git integration for presets, GitHub Actions, VSCode extension, browser capture extension, Zapier/Make connectors, REST + GraphQL APIs.

### Security & Compliance

* GDPR erasure, PII scanner, compliance presets, immutable audit logs, RBAC, field-level encryption, per-job ACLs, MFA for admin ops, signed manifests, consent flows for personal fields, export redaction templates, plugin sandbox (WASM).

### Monetization & Marketplace

* Pay-per-job billing, premium rulepacks marketplace, job credits, team seat pricing, usage reports, promo code system, affiliate tracking, demo generator for marketing.

### AI & Analytics

* ML-based seed suggestions, auto-tune transforms using historical hit rates, LLM-driven predicate generation, auto-summarize outputs, semantic dedupe (vector-based), anomaly detection, auto-documentation generation.

### Testing & QA

* Synthetic corpora generator, preflight dry-runs, regression harness, fuzz testing, rule coverage reports, mutation tests, deterministic test seeds, integration tests with Hashcat/John.

### Collaboration & Extensibility

* Shared preset libraries, commenting & review workflows, co-editing, delegated approvals, template ratings, issue tracker integration, plugin marketplace, SDKs (Python, JS, Go, Rust), WASM core engine for in-browser generation.

(Full feature flags list is included in repo `FEATURES.md` â€” see sample JSON at the end of this doc.)

---

## 4. Field Taxonomy & Schema Strategy

Weâ€™ll provide the field taxonomy in three layers:

1. **Category** â€” High level (Personal, Language, Humor, Music, Internet/Tech, Numbers, Keyboard, Fantasy, Science, Regional, Style, etc.)
2. **Field Group** â€” Mid-level (Names, Dates, MemeFormats, SongSnippets, IPPatterns, KeyboardWalks, Homoglyphs, etc.)
3. **Field** â€” Granular toggle (e.g., `first_name_male`, `birth_month_name`, `fav_meme_format`, `keyboard_walk_qwerty_diag`, `emoji_single`, `leet_full`).

### Field metadata (per field)

```json
{
  "id": "first_name_male",
  "category": "personal",
  "group": "names",
  "type": "string",
  "examples": ["Aaryan","Arjun"],
  "cardinality_estimate": 10000,
  "sensitivity": "low",
  "dependencies": [],
  "conflicts": [],
  "ui_hint": "text,autocomplete",
  "default_enabled": true
}
```

### Strategy to reach 1,500+ fields

* Start with the 500+ base fields already defined (common templates).
* Add 70 personality fields (memes/humor) and 120 advanced features toggles as feature flags.
* Expand language packs (per language add 50+ fields: stopwords, diacritics, transliteration rules).
* Add regional variants (per-country city lists, postal codes, area codes).
* Add domain-specific packs (finance, healthcareâ€”non-sensitive placeholders).
* Provide extensible field loader to import CSV/JSON packs so community/corporate customers can drop in their own 1000+ values.

---

## 5. Architecture

### High-level components

* **Frontend (Electron/React)** â€” UI, Visual Rule Builder, Live Preview, Preset management.
* **API Server (FastAPI / Async Python)** â€” Job submission, config validation, preset management, auth.
* **Job Scheduler** â€” Celery/RabbitMQ or Redis Queue; spawns workers (Kubernetes Jobs) for heavy generation.
* **Generator Worker** â€” Core combinator engine (Python), streaming transforms, dedupe (Bloom/RocksDB), checkpointing.
* **Storage** â€” S3/MinIO for outputs, Postgres for metadata, Redis for caches/queues, RocksDB for on-disk dedupe.
* **Auth & Billing** â€” OAuth2, NextAuth + Stripe integration.
* **Observability** â€” Prometheus + Grafana + Loki/ELK.

### Data flow (textual diagram)

```
[User] -> [GUI/CLI] -> [API Server] -> [Config Validator] -> [Scheduler]
    -> [Worker Pool] -> [Transform Engine] -> [Dedupe/Filter] -> [Sink (S3/File)]
    -> [Metadata / Checkpoints (Postgres/SQLite)] -> [Notifications/Webhooks]
```

### Worker internals (pipeline)

1. **Config validation**: Check field dependencies, estimate cardinality.
2. **Preflight**: If >threshold, run sample/canary job and prompt user.
3. **Partitioning**: Split combinatorial space across worker shards.
4. **Stream generation**: Seedâ†’Combinatorâ†’Transformsâ†’Filtersâ†’Dedupeâ†’Write chunk.
5. **Checkpoint**: Persist last emitted hash per shard.
6. **Finalize**: Assemble chunk manifests and upload metadata.

### Determinism & Resume

* Use stable hashing (BLAKE2b) of tokens and deterministic partitioning.
* Checkpoints store `(job_id, shard_id, last_hash, offset, bloom_state)` to resume exactly.

---

## 6. APIs & CLI Spec

### REST API (sample endpoints)

* `POST /api/v1/jobs` â€” Submit a generation job (body: preset/config).
* `GET /api/v1/jobs/{job_id}` â€” Job status & metadata.
* `GET /api/v1/jobs/{job_id}/chunks` â€” List output chunk manifests.
* `POST /api/v1/presets` â€” Save a preset.
* `GET /api/v1/presets/{id}` â€” Fetch preset.
* `POST /api/v1/presets/{id}/validate` â€” Validate preset & estimate size.
* `POST /api/v1/presets/{id}/sample` â€” Produce a sampled preview (N results).
* `GET /api/v1/features` â€” List feature flags.
* `POST /api/v1/auth/login` â€” OAuth token exchange.

### Example `POST /api/v1/jobs` payload (abridged)

```json
{
  "preset_id": "pentest_default_v1",
  "fields": ["company_name","dev_handles","first_name_male","birth_year"],
  "transforms": ["leet_basic","reverse","append_numbers_4"],
  "filters": {"min_len":8,"max_len":32,"charset":"ascii"},
  "output": {"type":"s3","bucket":"omni-results","path":"jobs/1234/"},
  "schedule": {"priority":"high"},
  "callbacks": {"webhook":"https://hooks.example/job-cb"}
}
```

### CLI (examples)

* `omni run --config preset.json --out ./out.gz --resume`
* `omni preview --preset pentest_default_v1 --sample 1000`
* `omni export-rule --preset x --format hashcat.rule`

---

## 7. UX / GUI design & screens

### Primary screens

1. **Dashboard** â€” Recent jobs, presets, usage metrics, billing.
2. **Preset Editor (Visual Rule Builder)** â€” Left: field tree with toggles; center: drag/drop rule canvas; right: field examples & dependency hints. Supports Monaco rule editor for DSL.
3. **Live Preview** â€” Stream first N results, show stats (entropy hist, char distribution).
4. **Job Submit** â€” Options for output, retention, encryption, and approvals.
5. **Job Monitor** â€” Per-job progress, per-shard throughput, logs, resume/cancel.
6. **Marketplace** â€” Browse/purchase rulepacks & templates.
7. **Admin** â€” RBAC, audit logs, billing, quotas.

### Interaction patterns

* **Progressive disclosure:** Most fields collapsed; power users expand groups.
* **Warnings:** Cardinality estimates displayed with visual risk (green/yellow/red).
* **Presets:** Shareable, versioned, forkable.
* **One-click canary:** Run a 1k sample to sanity-check before full job.

---

## 8. Data Formats, Outputs & Integrations

* **Primary outputs:** newline-separated UTF-8 TXT / gzipped TXT, JSONL (structured tokens), CSV (token + metadata columns), Parquet for analytics.
* **Hashcat/John integration:** export flags and rule files; compatible encodings.
* **S3 Hooks:** multipart, progress, per-chunk checksum.
* **SIEM:** Push job metadata & summary into Splunk/ELK.
* **Notification:** Slack/Discord webhooks; optional manual approval flows.

---

## 9. Scaling, Reliability & Security Design

### Scalability

* Kubernetes-based worker autoscaling.
* Partition strategy: split combinatorial axes (e.g., field groups) into shards.
* Dedupe: sharded Bloom filters persisted to RocksDB for memory efficiency.
* Hot presets cached in Redis for fast sampling.

### Reliability

* Checkpoints every N tokens or per-chunk boundary.
* Job snapshotting ensures deterministic replay.
* Canary jobs before full runs; auto-cancel on policy violations.

### Security

* TLS everywhere, OAuth2 + scopes, per-tenant KMS (Key Management Service) integration.
* Field-level encryption for sensitive fields.
* Audit logs immutable via append-only storage.
* Plugin runtime sandbox using WASM + syscall filter.
* RBAC enforced on API & GUI.

---

## 10. Compliance, Privacy & Legal Considerations

* **GDPR**: per-user data erasure endpoint; export redaction templates.
* **PII**: PII scanner warns when fields likely to contain PII and requires explicit confirmation.
* **Terms of Service & Acceptable Use:** users must confirm legal usage (testing only on authorized targets). Company-level legal team to craft TOS and export controls.
* **Marketplace vetting:** review paid rulepacks to avoid malicious content; sign & certify packs.

---

## 11. Testing Strategy & QA Plan

* **Unit tests**: transforms, combinator engine, filters.
* **Integration tests**: end-to-end small job generation, resume flow.
* **Performance tests**: IO throughput, Bloom filter scaling, distributed generation.
* **Fuzz tests**: malformed DSL, regex edge cases (catastrophic backtracking).
* **Security tests**: plugin sandbox escape attempts, RBAC bypass, input validation.
* **CI pipeline**: run deterministic seeds, assert sample outputs.
* **Canary & Staging**: small production-like cluster for heavy jobs.

---

## 12. Roadmap & Milestones (90-day plan, Pentester-first)

### Phase 0 â€” Week 0 (Project Init)

* Repo bootstrap, basic README, field schema v0 (500 fields), basic CLI.

### Phase 1 â€” Week 1â€“4 (MVP)

* Implement streaming single-node generator (clean approach).
* Implement transforms: leet, reverse, padding, simple homoglyphs.
* SQLite checkpointing, gz sink, basic Bloom dedupe.
* CLI commands: run, preview, resume.
* Docs & sample presets (pentest_default).

### Phase 2 â€” Week 5â€“8 (Scale & UX)

* API server (FastAPI), job scheduler (Celery).
* Electron GUI with Visual Rule Builder (preview pane).
* Cardinality estimator, canary sample mode, preflight checks.
* S3 sink, chunking, per-chunk checksums.

### Phase 3 â€” Week 9â€“12 (Enterprise & Integrations)

* RBAC, audit logs, KMS integration, GDPR endpoints.
* Hashcat/John exports, VSCode extension, GitHub Actions orb.
* Marketplace MVP (upload/publish rulepacks).

### Milestones + Deliverables

* End of Week 4: CLI + streaming generator + sample presets.
* End of Week 8: GUI Beta + API server + S3 output.
* End of Week 12: Enterprise features + marketplace MVP.

---

## 13. Developer Guide & Folder Structure

```
/omniwordlist
â”œâ”€ /docs
â”œâ”€ /backend
â”‚  â”œâ”€ api/              # FastAPI app
â”‚  â”œâ”€ jobs/             # Job scheduler + worker code
â”‚  â”œâ”€ generator/        # combinator engine, transforms
â”‚  â”œâ”€ storage/          # S3 / local storage adapters
â”‚  â””â”€ tests/
â”œâ”€ /cli
â”‚  â””â”€ omni (entrypoint)
â”œâ”€ /frontend
â”‚  â”œâ”€ electron-app
â”‚  â””â”€ web/
â”œâ”€ /plugins
â”œâ”€ /presets
â”œâ”€ /field-packs
â”œâ”€ /infrastructure
â”‚  â”œâ”€ k8s/
â”‚  â””â”€ terraform/
â””â”€ docker-compose.yml
```

### Key repositories / modules

* `generator/engine.py` â€” pipeline orchestration (seedâ†’transformâ†’filterâ†’sink)
* `generator/transforms/*` â€” specific transforms (leet, homoglyph, phonetic)
* `generator/dedupe/*` â€” Bloom/RocksDB adapters
* `api/jobs.py` â€” job submission & validation
* `cli/omni` â€” CLI wrapper to call API or run local engine
* `frontend/visual-builder` â€” React components & Monaco integration

---

## 14. Sample Configs & Presets

### Example `pentest_default.json`

```json
{
  "name": "pentest_default_v1",
  "fields": ["company_name", "dev_handles", "first_name_male", "last_name", "birth_year", "common_suffixes"],
  "transforms": ["leet_basic","append_numbers_best_4","titlecase_names"],
  "filters": {"min_len":8,"max_len":30,"charset":"ascii"},
  "output": {"type":"file","path":"./out/pentest_default_v1.gz"}
}
```

### Example `meme_humor_pack.json`

```json
{
  "name": "meme_humor_pack",
  "fields": ["fav_meme_format","favorite_joke","favorite_pun","go_to_reaction_emoji"],
  "transforms": ["emoji_insertion","random_case"],
  "filters": {"min_len":3,"max_len":140},
  "output": {"type":"jsonl","path":"./out/meme_pack.jsonl"}
}
```

---

## 15. Monetization & Ops Playbook

* **Pricing Tiers:** Free (limited lines/day), Pro ($49/mo), Team ($199/mo), Enterprise (custom).
* **Monetizable features:** Pay-per-job heavy exports, premium transforms (ML phonetics), marketplace rulepacks, priority SLA.
* **Marketing:** OSS launch of CLI core on GitHub (MIT), blog posts (Hacker News, r/netsec), demos with bug-bounty teams, webinars.
* **Support & Onboarding:** Docs + video tutorials, community Discord, paid enterprise onboarding.
* **SLA & Ops:** K8s cluster with autoscaling, backups (S3 lifecycle), incident runbooks.

---

## 16. Action Items â€” Immediate (copy/paste checklist)

1. Create GitHub repo `omniwordlist` with `README.md`, `CONTRIBUTING.md`, and license.
2. Implement `generator/engine.py` streaming pipeline (use clean approach code pattern).
3. Implement transforms: `leet_basic`, `reverse`, `append_numbers_best_4`, `emoji_insertion`.
4. Add SQLite checkpointing & Bloom dedupe adapter with RocksDB fallback.
5. Create `presets/pentest_default.json` and `presets/meme_humor_pack.json`.
6. Build CLI `omni run --config` and `omni preview --sample`.
7. Draft `FEATURES.md` listing all 120+ advanced feature flags with short descriptions.
8. Build cardinality estimator & preflight sample runner (1k lines).
9. Create issue templates and a project board for Phase 1 tasks.
10. Prepare release v0.1 (CLI only) and an initial demo video.

---

## Appendices

### A. Feature Flags Example (JSON)

```json
{
  "features": {
    "adaptive_combinator_cap": true,
    "weighted_combinator_generation": true,
    "homoglyph_injection_engine": true,
    "signed_encrypted_artifacts": false,
    "distributed_generation": false,
    "visual_rule_builder": false,
    "gdpr_data_erasure": false,
    "ml_seed_suggestion": false,
    "plugin_system_wasm": false
  }
}
```

### B. Example Job Lifecycle

1. User uploads/creates preset.
2. User requests `preview` â†’ system runs sample job (1k).
3. User approves full job â†’ system partitions job, spins up workers.
4. Workers stream tokens to S3 with per-chunk checksums.
5. On completion, job metadata + manifest created; user notified.

### C. Security & AUP snippet (to include in product)

> Users must confirm they have authorization to test any systems, accounts, or targets against which generated wordlists are used. OmniWordlist Pro is a defensive tool. Usage against unauthorized targets is prohibited.

---

## Closing / Next Steps

I can now:

* scaffold the repo with the CLI MVP, streaming generator, checkpointing, and sample presets; **or**
* produce the full `FEATURES.md` (120+ features) and `FIELDS_SCHEMA.json` (1,500+ field entries ready to import); **or**
* create the Electron visual rule builder mockups + Monaco DSL examples.

Which of these should I generate *right now* and produce as files you can download and run?
